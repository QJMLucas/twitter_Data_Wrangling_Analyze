# twitter_project
Data wrangling and analyze with twitter data

Things been done for the project:

- Cleaned the data quality issues in the 'twitter-archive-enhanced.csv' file. Cleaned the data quality issues within the file.

- used Tweepy API to query the data, such as: tweet ID, retweet count and favourite count from Twitter 
  account: @dog_rates , also known as WeRateDogs. The result is stored into the 'tweet_json.txt' file

- Loaded the dataset from Udacity's servers using the Request library and combined it with the file that I extracted previously from
  #dog_rates based on their tweet ID.
  
- 'wrangle_act.ipynb': This file contains the code for data wrangling and analyzing processes.

- Provided insights and visualisations based on the file 'twitter_archive_master.csv' which is the combined version for those data
  provided, requested and extracted from various sources.
